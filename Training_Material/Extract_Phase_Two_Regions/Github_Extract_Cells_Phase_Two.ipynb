{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc1ce43",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to import any necessary libraries or packages needed for the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157435d",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to extract possible \"cells\" for manual classification.\n",
    "\n",
    "The user will have to change the channel_Directory, network_File_Path, and region_Save_Location variables to link to their relevant directories. Notice here how we use the phase one network to identify potential cell candidates, which we will then classify by hand later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_Directory = \"\"\n",
    "network_File_Path = \"\"\n",
    "region_Save_Location = \"\"\n",
    "\n",
    "network = tf.keras.models.load_model(network_File_Path)\n",
    "\n",
    "def standard_norm(img):\n",
    "    height, width, channels = img.shape\n",
    "    for channel in range(channels):\n",
    "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "    return img\n",
    "\n",
    "def recolor_Image(img):\n",
    "    maximum = np.mean(img) + 4*np.std(img)\n",
    "    minimum = np.mean(img) - 4*np.std(img)\n",
    "    color_Adjusted_Image = (img - minimum)/(maximum - minimum)\n",
    "    color_Adjusted_Image[color_Adjusted_Image < 0] = 0\n",
    "    color_Adjusted_Image[color_Adjusted_Image > 1] = 1\n",
    "    return color_Adjusted_Image\n",
    "\n",
    "count = 0\n",
    "region_Number = 0\n",
    "cell_Capture_Range = 40\n",
    "for image_Name in os.listdir(channel_Directory):\n",
    "    print(\"Analyzing \" + image_Name[:-4])\n",
    "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
    "    if np.max(full_Channel) == int(np.max(full_Channel)) and len(str(np.max(full_Channel))) == len(str(int(np.max(full_Channel)))):\n",
    "        full_Channel = full_Channel.copy()/255.\n",
    "    if len(np.shape(full_Channel)) == 2:\n",
    "        full_Channel = cv2.cvtColor(full_Channel, cv2.COLOR_GRAY2RGB)\n",
    "    if np.shape(full_Channel)[2] == 4:\n",
    "        full_Channel = full_Channel.copy()[:,:,0:3]\n",
    "    full_Channel = recolor_Image(full_Channel.copy())\n",
    "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
    "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    else:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    full_Channel_Resized[full_Channel_Resized < 0] = 0\n",
    "    full_Channel_Resized[full_Channel_Resized > 1] = 1\n",
    "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
    "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
    "\n",
    "    x_Slider = 0\n",
    "    y_Slider = 0\n",
    "    output_Array = np.zeros((128,128))\n",
    "    for i in range(vertical_Tiles):\n",
    "        x_Slider = 150*i\n",
    "        for j in range(horizontal_Tiles):\n",
    "            y_Slider = 150*j\n",
    "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]\n",
    "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
    "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
    "            output = network.predict(current_Tile_Normalized)\n",
    "\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
    "            \n",
    "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
    "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
    "            output_Array = np.zeros((128,128))\n",
    "    for i in range(image_Height_Resized):\n",
    "        for j in range(image_Width_Resized):\n",
    "            if output_Image[i,j] != 0:\n",
    "                output_Image[i,j] = 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    blobs, number_Of_Blobs = label(output_Image)\n",
    "    properties = measure.regionprops(blobs)\n",
    "    \n",
    "    for prop in properties:\n",
    "        count = count + 1\n",
    "        if round(prop.centroid[0]) < cell_Capture_Range:\n",
    "            if round(prop.centroid[1]) < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,0:cell_Capture_Range]  \n",
    "            elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,image_Width_Resized - cell_Capture_Range:image_Width_Resized]   \n",
    "            else:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]\n",
    "        elif round(prop.centroid[1]) < cell_Capture_Range:\n",
    "            if image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,0:cell_Capture_Range]\n",
    "            else:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),0:cell_Capture_Range]\n",
    "        elif image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "            if image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,image_Width_Resized - cell_Capture_Range:image_Width_Resized]\n",
    "            else:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]              \n",
    "        elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),image_Width_Resized - cell_Capture_Range:image_Width_Resized]            \n",
    "        else:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]               \n",
    "        plt.imsave(region_Save_Location + \"/Region_\" + str(count) + \".png\",region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
