{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxe0PubMzS+E7KVbJ1ofZy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hincz-lab/motion-blur-microscopy/blob/main/Analysis_Material/Video_Analysis/MBM_videoprocessing_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Click if you would like to access your personal Google Drive (recommended for processing large video files)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P4NdtfhBl_u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "link to .h5 model for SRBC Laminin and CAR-T P-selectin: https://drive.google.com/file/d/1DtZAM7zaNCSko5HIue_bv5DRUytJzkxU/view?usp=sharing \n",
        "\n",
        "link to .h5 model for CAR-T E-selectin: https://drive.google.com/file/d/1NMnqgRUBBwr-Z5kZoQNU2TZNPvDPaw93/view?usp=sharing"
      ],
      "metadata": {
        "id": "Ekw3uQ_5wth1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qOlUO4EJ8aC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "#@markdown After you run this cell, click folder icon (left), go to 'content', and go to 'video_analysis'. Populate this folder with the .h5 segmentation model file and the video file (.avi or .mp4) you would like to run the analysis on. If no video is uploaded, you will be prompted to paste a path in the next step.\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.ndimage import label\n",
        "from skimage import measure\n",
        "import matplotlib.pyplot as plt\n",
        "import os, csv\n",
        "import bisect\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.spatial import ConvexHull\n",
        "from matplotlib.path import Path\n",
        "import tkinter as tk\n",
        "import glob\n",
        "\n",
        "structure = [[1,1,1],\n",
        "             [1,1,1],\n",
        "             [1,1,1]] #2-connectivity\n",
        "\n",
        "def standard_norm(img):\n",
        "    height, width, channels = img.shape\n",
        "    for channel in range(channels):\n",
        "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
        "    return img\n",
        "\n",
        "def dist(centroids): #centroids = list of points\n",
        "  poss_distances = []\n",
        "  for c in range(len(centroids)-1):\n",
        "    cent = centroids[c]\n",
        "    centroids2 = centroids[c+1:] #every point after cent[x for x in centroids if x != cent]\n",
        "    for cent2 in centroids2:\n",
        "      poss_distances.append(np.sqrt( (cent[0] - cent2[0])**2 + (cent[1] - cent2[1])**2 ))\n",
        "  return poss_distances #a list of distances\n",
        "\n",
        "#iterate through all coords\n",
        "def shortest_dist(listofarrs): #two arrays, allowed to be any length\n",
        "  distances = []\n",
        "  array1 = listofarrs[0].tolist() #a list of points\n",
        "  array2 = listofarrs[1].tolist()\n",
        "  for point1 in array1:\n",
        "    for point2 in array2:\n",
        "      distances.append(dist([point1,point2])[0])\n",
        "  return min(distances)\n",
        "\n",
        "def return_indices(d,N): #d=index of distance list N=total num. of blobs\n",
        "  #check if d is in a range\n",
        "  start = 0\n",
        "  end = (N-1)\n",
        "  for n in range(2,N+1):\n",
        "    if d in range(start,end):\n",
        "      return n-2, n+(d-start)-1 \n",
        "      break\n",
        "    else:\n",
        "      start = end\n",
        "      end += (N-n)\n",
        "\n",
        "def eccentricity(hull): #hull=ConvexHull object\n",
        "  x, y = np.meshgrid(np.arange(min(hull.points[hull.vertices,0]),max(hull.points[hull.vertices,0])+1), np.arange(min(hull.points[hull.vertices,1]),max(hull.points[hull.vertices,1])+1)) # make a canvas with coordinates\n",
        "  x, y = x.flatten(), y.flatten()\n",
        "  temp_points = np.vstack((x,y)).T \n",
        "\n",
        "  points = []\n",
        "  # include both cw and ccw to include as many points as possible\n",
        "  p = Path(hull.points[::-1]) # cw\n",
        "  grid = p.contains_points(temp_points, radius=0.1)\n",
        "  grid2 = measure.points_in_poly(temp_points,hull.points[hull.vertices][::-1])\n",
        "  for g in range(len(grid)):\n",
        "    if grid[g]==True or grid2[g]==True:\n",
        "      points.append(np.array(temp_points[g]))\n",
        "  p = Path(hull.points) # ccw\n",
        "  grid = p.contains_points(temp_points, radius=0.01)\n",
        "  grid2 = measure.points_in_poly(temp_points,hull.points[hull.vertices])\n",
        "  for g in range(len(grid)):\n",
        "    if grid[g]==True or grid2[g]==True:\n",
        "      points.append(np.array(temp_points[g]))\n",
        "  points = np.array(points)\n",
        "\n",
        "  #take above points and make a mini-image w all points labeled 1, and all other points labeled 0\n",
        "  y_len  = int(max(hull.points[hull.vertices,0]) - min(hull.points[hull.vertices,0]) +1)\n",
        "  x_len = int(max(hull.points[hull.vertices,1]) - min(hull.points[hull.vertices,1]) +1)\n",
        "  temp_image = np.zeros((y_len,x_len))\n",
        "  for point in points:\n",
        "    temp_image[int(point[0]-min(hull.points[hull.vertices,0]))][int(point[1]-min(hull.points[hull.vertices,1]))] = 1\n",
        "  # use measure.regionprops to get eccentricity (double check num of blobs=1)\n",
        "  outarray,numOfBlobs = label(temp_image,structure)\n",
        "  properties = measure.regionprops(outarray)\n",
        "  if numOfBlobs==0:\n",
        "    print(\"ERROR: detecting 0 blobs!\") #STOP RUNNING CODE IF THIS COMES UP\n",
        "    ecc = 0\n",
        "  else:\n",
        "    eccs = [prop.eccentricity for prop in properties]\n",
        "    ecc = eccs[0] #should only be 1!\n",
        "  return ecc\n",
        "\n",
        "### assuming we are already in the local directory\n",
        "# if not, put cd command to home folder\n",
        "# ! cd /home\n",
        "os.mkdir('video_analysis')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the cell below will prompt you to enter the necessary inputs to run the program."
      ],
      "metadata": {
        "id": "zQLVt0_jK54D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "# Begin video processing algortithm\n",
        "# video file path (type .avi) - CHANGE THIS PATH\n",
        "video_path = glob.glob('video_analysis/*.avi') + glob.glob('video_analysis/*.mp4')\n",
        "if len(video_path)>1:\n",
        "  print(\"More than one video to choose from. Specify which video to use by pasting the path: \")\n",
        "  video_path = input()\n",
        "elif len(video_path)==1:\n",
        "  video_path = video_path[0]\n",
        "else: #zero found\n",
        "  print(\"Paste the path to the video you would like to process: \")\n",
        "  video_path = input()\n",
        "\n",
        "model_path = glob.glob('video_analysis/*.h5')[0]\n",
        "if len(model_path)>1:\n",
        "  print(\"More than one model to choose from. Specify which model to use by pasting the path: \")\n",
        "  model_path = input()\n",
        "else:\n",
        "  model_path = model_path[0]\n",
        "\n",
        "# load model from new_model file\n",
        "new_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "autoconvex = ''\n",
        "while True:\n",
        "  autoconvex = input(\"Would you like to automatically take the convex hull of all regions? Enter y/n: \")\n",
        "  if autoconvex.lower() == 'y':\n",
        "      print('Automatically take convex hull of all connected regions')\n",
        "      break\n",
        "  elif autoconvex.lower() == 'n':\n",
        "      break\n",
        "  else:\n",
        "      print('Error: answer invalid.')\n",
        "      continue\n",
        "\n",
        "celltype = ''\n",
        "while True:\n",
        "  celltype = input(\"Which cell type is present? If multiple cell types present, please enter smallest cell type. Accepted answers: CART, SRBC, CUSTOM: \")\n",
        "  if celltype.lower() == 'cart':\n",
        "      thresh = 40\n",
        "      init_thresh = 40\n",
        "      ghost_frames=9\n",
        "      break\n",
        "  elif celltype.lower() == 'srbc':\n",
        "      thresh = 45\n",
        "      init_thresh = 90\n",
        "      ghost_frames=2\n",
        "      break\n",
        "  elif celltype.lower() == 'custom':\n",
        "      thresh = int(input(\"Enter minimum threshold for regions to be considered: \"))\n",
        "      init_thresh = int(input(\"Enter attachment threshold: \"))\n",
        "      ghost_frames= int(input(\"Enter maximum number of frames cells can go undetected: \"))\n",
        "      break\n",
        "  else:\n",
        "      print('Error: answer invalid.')\n",
        "      continue\n",
        "\n",
        "limit_frames = ''\n",
        "min_frames=0\n",
        "max_frames=1000000\n",
        "while True:\n",
        "  limit_frames = input(\"Would you like to limit the frames analyzed? Enter y/n: \")\n",
        "  if limit_frames.lower() == 'y':\n",
        "      print('Limiting frames of video to be analyzed.')\n",
        "      limit_frames=True\n",
        "      min_frames=int(input(\"Define minimum frame number: \"))\n",
        "      max_frames=int(input(\"Define maximum frame number: \"))\n",
        "      break\n",
        "  elif limit_frames.lower() == 'n':\n",
        "      limit_frames = False\n",
        "      break\n",
        "  else:\n",
        "      print('Error: answer invalid.')\n",
        "      continue\n",
        "\n",
        "data_filename = video_path.split(\"/\",-1)[-1][:-4].replace(' ', '_') +'_master_static.csv'  \n",
        "\n",
        "try:\n",
        "  os.remove(data_filename)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "with open(data_filename,'a') as fd:\n",
        "    fd.write('frame' + ',' + 'row' + ',' + 'column' + ',' + 'area' + ',' + 'eccentricity' + ',' + 'rel grey color' + '\\n')\n",
        "\n",
        "# convert video to a sequence of images\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_num = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame_num +=1\n",
        "    # if frame is read correctly ret is True\n",
        "    if not ret:\n",
        "        print(frame_num-1, \"is the max number of frames!\")\n",
        "        max_frames = frame_num-1\n",
        "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "        break\n",
        "    if limit_frames==True and frame_num >= max_frames:\n",
        "      break\n",
        "    elif limit_frames==True and frame_num <= min_frames:\n",
        "      pass\n",
        "    #make prediction on \"frame\", collecting size and location of blobs\n",
        "    else:\n",
        "        #print(\"Analyzing frame \", frame_num)\n",
        "        test_Image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        if len(np.shape(test_Image)) == 2:\n",
        "            test_Image = cv2.cvtColor(test_Image, cv2.COLOR_GRAY2RGB)\n",
        "        image_Height, image_Width, channels = np.shape(test_Image)\n",
        "        if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
        "            test_Image_Resized = cv2.resize(test_Image,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "            vertical_Tiles = int(np.floor(image_Height/150))\n",
        "            horizontal_Tiles = int(np.floor(image_Width/150))\n",
        "        elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
        "            test_Image_Resized = cv2.resize(test_Image,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "            vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
        "            horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
        "        elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
        "            test_Image_Resized = cv2.resize(test_Image,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "            vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
        "            horizontal_Tiles = int(np.floor(image_Width/150))\n",
        "        else:\n",
        "            test_Image_Resized = cv2.resize(test_Image,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
        "            vertical_Tiles = int(np.floor(image_Height/150))\n",
        "            horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
        "        image_To_Use = cv2.cvtColor(test_Image_Resized, cv2.COLOR_BGR2GRAY)\n",
        "        image_Height_Resized, image_Width_Resized, channels = np.shape(test_Image_Resized)\n",
        "        output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
        "\n",
        "        x_Slider = 0\n",
        "        y_Slider = 0\n",
        "        output_Array = np.zeros((128,128))\n",
        "        for i in range(vertical_Tiles):\n",
        "            x_Slider = 150*i\n",
        "            for j in range(horizontal_Tiles):\n",
        "                y_Slider = 150*j\n",
        "                current_Tile = test_Image_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]/255\n",
        "                current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
        "                current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
        "                current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
        "                output = new_model.predict(current_Tile_Normalized, verbose=0)\n",
        "                for i in range(128):\n",
        "                    for j in range(128):\n",
        "                        output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
        "                output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
        "                output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
        "                output_Array = np.zeros((128,128))\n",
        "        for i in range(image_Height_Resized):\n",
        "            for j in range(image_Width_Resized):\n",
        "                if output_Image[i,j] != 0:\n",
        "                    output_Image[i,j] = 1\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        blobs, _ = label(output_Image, structure=structure) # whole channel image\n",
        "        properties = measure.regionprops(blobs)\n",
        "        blob_Sizes = [prop.area for prop in properties if prop.area > thresh]\n",
        "        centroids = [prop.centroid for prop in properties if prop.area > thresh]\n",
        "        eccentricities = [prop.eccentricity for prop in properties if prop.area > thresh]\n",
        "        clusters = [prop.coords for prop in properties if prop.area > thresh]\n",
        "        something2 = len(centroids)\n",
        "\n",
        "        # Check if any centroids w/in 50 pixels of each other\n",
        "        indices_to_del = [] #list of indices\n",
        "        distances = dist(centroids)\n",
        "        for d in range(len(distances)):\n",
        "          dis = distances[d]\n",
        "          if dis<50:\n",
        "            # get indexes of the two blobs\n",
        "            idx1,idx2 = return_indices(d,len(centroids))\n",
        "            indices_to_del.extend([idx1,idx2])\n",
        "            points = [[prop.coords for prop in properties][idx1],[prop.coords for prop in properties][idx2]]\n",
        "            if shortest_dist(points)<=5:\n",
        "              #compute convex hull for points\n",
        "              hull = ConvexHull(list(points[0])+list(points[1]))\n",
        "              #append new centroid, area, and eccentricity to end of lists\n",
        "              blob_Sizes.append(hull.volume)\n",
        "              centroids.append((np.mean(hull.points[hull.vertices,0]),np.mean(hull.points[hull.vertices,1])))\n",
        "              eccentricities.append(eccentricity(hull))\n",
        "              clusters.append(hull.points)\n",
        "        if indices_to_del:\n",
        "          blob_Sizes = [i for j, i in enumerate(blob_Sizes) if j not in indices_to_del]\n",
        "          centroids = [i for j, i in enumerate(centroids) if j not in indices_to_del]\n",
        "          eccentricities = [i for j, i in enumerate(eccentricities) if j not in indices_to_del]\n",
        "          clusters = [i for j, i in enumerate(clusters) if j not in indices_to_del]\n",
        "          \n",
        "        if autoconvex.lower()=='y':\n",
        "          # take convex hull of all other cells\n",
        "          for cell in range(len(centroids)):\n",
        "              points = clusters[cell]\n",
        "              hull = ConvexHull(list(points))\n",
        "              blob_Sizes[cell] = hull.volume\n",
        "              centroids[cell] = (np.mean(hull.points[hull.vertices,0]),np.mean(hull.points[hull.vertices,1]))\n",
        "              eccentricities[cell] = eccentricity(hull)\n",
        "              clusters[cell] = hull.points\n",
        "\n",
        "        # relative average grayscale value of each cell\n",
        "        rel_greyscale_vals = []\n",
        "        for cluster in clusters:\n",
        "            pixelvals = []\n",
        "            for cpoint in cluster:\n",
        "                pixelvals.append(image_To_Use[int(cpoint[0])][int(cpoint[1])])\n",
        "            rel_greyscale_vals.append(np.mean(pixelvals) - np.mean(image_To_Use))\n",
        "\n",
        "        # csv w/ each row: frame, , location[0], location[1], area, eccentricity\n",
        "        # more raw of data lol\n",
        "        # print(len(centroids))\n",
        "        for i in range(len(centroids)):\n",
        "            with open(data_filename,'a') as fd:\n",
        "                fd.write(str(frame_num) + ',' + str(centroids[i][0]) + ',' + str(centroids[i][1]) + ',' + str(blob_Sizes[i]) + ',' + str(eccentricities[i]) + ',' + str(rel_greyscale_vals[i]) + \"\\n\")\n",
        "\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\"\"\"\"SIZE VARIANCE ANALYSIS: initial attachment follows adhesion size threshold, in following frames looking for same centroid at least the minimum size for cell of interest\"\"\"\n",
        "# if a cell moves, it is *not adhered*. want location to stay the same -- record new location instances in each frame\n",
        "# csv: frame, row, column, area, eccentricity\n",
        "\n",
        "adhesion_data = []\n",
        "other_data = [] #elements:[frame_num, location, eccentricity, size, rolling?, color]\n",
        "cell_num = 0\n",
        "count = 0\n",
        "with open(data_filename, 'r') as csvfile:\n",
        "  for row in list(csv.reader(csvfile))[1:]:\n",
        "    frame_num = int(row[0])\n",
        "    if frame_num>=min_frames and frame_num<=max_frames:\n",
        "      size = float(row[3])\n",
        "      if size >= thresh:\n",
        "          for d in range(1,ghost_frames+2): #check if cell has disappeared for some time\n",
        "              temp_data = [dat for dat in other_data if dat[0]==frame_num-d]# checking previous frame\n",
        "              # print(row)\n",
        "              location = (float(row[1]),float(row[2])) # allow cell to be +/- 5 to be the same\n",
        "              ecc = float(row[4])\n",
        "              color = float(row[5])\n",
        "              # check if cell rolls left, can only move +/- 5 up or down\n",
        "              roll_poss = [loc[1] for loc in temp_data if loc[1][1]-30<=location[1] and loc[1][1]-5>location[1]]\n",
        "              roll_x_poss = [r_p for r_p in roll_poss if r_p[0]>=location[0]-5 and r_p[0]<=location[0]+5]\n",
        "              roll_left = []\n",
        "              for r_xp in roll_x_poss:\n",
        "                idxs = [i for i, x in enumerate(temp_data) if x[1] == r_xp]\n",
        "                for id in idxs:\n",
        "                  if size>=1:#(temp_data[id][3] - (temp_data[id][3]*0.5)) and size<=(temp_data[id][3] + (temp_data[id][3]*0.5)): #check size\n",
        "                    roll_left.append(1)\n",
        "              if roll_left:\n",
        "                roll = 'yes'\n",
        "              else:\n",
        "                roll = 'no'\n",
        "              # check if location inside a rectangle & check size\n",
        "              lower_bound = (location[0]-5, location[1]-5)\n",
        "              upper_bound = (location[0]+5, location[1]+5)\n",
        "              lower_bound_i = bisect.bisect_left([loc[1] for loc in temp_data], lower_bound)\n",
        "              upper_bound_i = bisect.bisect_right([loc[1] for loc in temp_data], upper_bound, lo=lower_bound_i)\n",
        "              nums = [loc[1] for loc in temp_data][lower_bound_i:upper_bound_i]\n",
        "              sizes = [loc[3] for loc in temp_data][lower_bound_i:upper_bound_i]\n",
        "              final_nums = []\n",
        "              for nn in range(len(nums)):\n",
        "                num = nums[nn]\n",
        "                low_size = sizes[nn] - (sizes[nn]*0.5) \n",
        "                high_size = sizes[nn] + (sizes[nn]*0.5) #size w/in 50% of initial size\n",
        "                if num[0]>=lower_bound[0] and num[0]<=upper_bound[0] and num[1]>=lower_bound[1] and num[1]<=upper_bound[1]:\n",
        "                  if size>=1:#low_size and size<=high_size:\n",
        "                    final_nums.append(num)\n",
        "              if final_nums: #enter this if cell was in previous frame -- check if size w/in 50%\n",
        "                psn = [loc[1] for loc in other_data].index(final_nums[-1])\n",
        "                adhesion_data.append(adhesion_data[psn])\n",
        "                other_data.append([frame_num, location, ecc, size, roll, color])\n",
        "                break\n",
        "              elif not final_nums and roll=='yes':\n",
        "                psn = [loc[1] for loc in other_data].index(roll_x_poss[-1])\n",
        "                adhesion_data.append(adhesion_data[psn])\n",
        "                other_data.append([frame_num, location, ecc, size, roll, color])\n",
        "                break\n",
        "              elif not final_nums and roll=='no' and d==10: #check frame before\n",
        "                #if size>=init_thresh:\n",
        "                adhesion_data.append(cell_num)\n",
        "                other_data.append([frame_num, location, ecc, size, roll, color])\n",
        "                cell_num += 1\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "fps = 1/1.2\n",
        "ecc_data, ecc_std, final_data = [], [], [] # list of corresponding avg ecc, stdev ecc, and adhesion times\n",
        "ecc_data_end, ecc_std_end, end_of_data = [], [], []\n",
        "toss = 1\n",
        "for cell in np.unique(adhesion_data):\n",
        "  if adhesion_data.count(cell)<=toss:\n",
        "    pass\n",
        "  else:\n",
        "    indices = [i for i, x in enumerate(adhesion_data) if x == cell] #should return all indices of a specific cell label\n",
        "    eccs = []\n",
        "    for j in indices:\n",
        "      eccs.append(other_data[j][2])\n",
        "    if other_data[j][0]==max_frames:\n",
        "      ecc_data_end.append(np.mean(eccs))\n",
        "      ecc_std_end.append(np.std(eccs))\n",
        "      end_of_data.append(adhesion_data.count(cell))\n",
        "    else:\n",
        "      ecc_data.append(np.mean(eccs))\n",
        "      ecc_std.append(np.std(eccs))\n",
        "      final_data.append(adhesion_data.count(cell))\n",
        "\n",
        "\"\"\"Write to .csv cell#, frame attached, frame detached, avg ecc, stddev ecc, avg size, avg location, rolling?\"\"\"\n",
        "finalized_data_filename = data_filename[:-10] + 'dynamic.csv'\n",
        "\n",
        "try:\n",
        "  os.remove(finalized_data_filename)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "with open(finalized_data_filename,'a') as fd:\n",
        "  fd.write('cell number' + ',' + 'frame attached' + ',' + 'frame detached' + ',' + 'average eccentricity' + ',' +\n",
        "           'average size' + ',' + 'average location[0]' + ',' + 'average location[1]' + ',' + 'rolling?' + ',' +\n",
        "           'start loc[0]' + ',' + 'start loc[1]' + ',' + 'end loc [0]' + ',' + 'end loc[1]' + ',' + 'avg rel grey color' + '\\n')\n",
        "  \n",
        "for cell in np.unique(adhesion_data):\n",
        "  indices = [i for i, x in enumerate(adhesion_data) if x == cell]\n",
        "  rolling = 'no'\n",
        "  frame_att = other_data[indices[0]][0]\n",
        "  frame_det = other_data[indices[-1]][0]\n",
        "  ecc_data = []\n",
        "  size_data = []\n",
        "  loc_data = []\n",
        "  color_data = []\n",
        "  for idx in indices:\n",
        "    if other_data[idx][4]=='yes': #if rolling at any point, label as rolling\n",
        "      rolling = 'yes'\n",
        "    ecc_data.append(other_data[idx][2])\n",
        "    size_data.append(other_data[idx][3])\n",
        "    loc_data.append(other_data[idx][1])\n",
        "    color_data.append(other_data[idx][5])\n",
        "  #print(\"Stdev of cell size\", np.std(size_data))\n",
        "  avg_loc = [sum(x)/len(x) for x in zip(*loc_data)]\n",
        "  with open(finalized_data_filename,'a') as fd:\n",
        "    fd.write(str(cell) + ',' + str(frame_att) + ',' + str(frame_det) + ',' + str(np.mean(ecc_data)) + ',' +\n",
        "             str(np.mean(size_data)) + ',' + str(avg_loc[0]) + ',' + str(avg_loc[1]) + ',' + rolling + ',' + \n",
        "             str(loc_data[0][0]) + ',' + str(loc_data[0][1]) + ',' + str(loc_data[-1][0]) + ',' + str(loc_data[-1][1]) + \n",
        "             ',' + str(np.mean(color_data)) + '\\n')\n",
        "    \n",
        "# write over raw data file to include cell # as first element of each row\n",
        "try:\n",
        "  os.remove(data_filename)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "with open(data_filename,'a') as fd:\n",
        "    fd.write('cell num' + ',' + 'frame' + ',' + 'locatin[0]' + ',' + 'location[1]' + ',' + 'area' + ',' + 'eccentricity' + ',' + 'rel grey color' + '\\n')\n",
        "    for jj in range(len(adhesion_data)):\n",
        "        fd.write(str(adhesion_data[jj]) + ',' + str(other_data[jj][0]) + ',' + str(other_data[jj][1][0]) + ',' + str(other_data[jj][1][1]) +\n",
        "                 ',' + str(other_data[jj][3]) + ',' + str(other_data[jj][2]) + ',' + str(other_data[jj][5]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twbXhWGdc-hL",
        "outputId": "d400213e-7079-4d7e-c890-4200a9733a35",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More than one model to choose from. Specify which model to use by pasting the path: \n",
            "/content/video_analysis/Phase_One_Network_E_Selectin_Car_T.h5\n",
            "Would you like to automatically take the convex hull of all regions? Enter y/n: y\n",
            "Automatically take convex hull of all connected regions\n",
            "Which cell type is present? If multiple cell types present, please enter smallest cell type. Accepted answers: CART, SRBC, CUSTOM: CART\n",
            "Would you like to limit the frames analyzed? Enter y/n: y\n",
            "Limiting frames of video to be analyzed.\n",
            "Define minimum frame number: 1\n",
            "Define maximum frame number: 10\n",
            "Analyzing frame  1\n",
            "Analyzing frame  2\n"
          ]
        }
      ]
    }
  ]
}