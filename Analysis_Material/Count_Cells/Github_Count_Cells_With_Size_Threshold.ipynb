{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581f884a",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to import any libraries and packages required to run the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf2a08",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to count cells in a set of MBM images or MBM video frames, using a size threshold.\n",
    "\n",
    "The user will need to adjust the base_Directory variable, and carefully note the directory structure when using this code for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Directory = \"\"\n",
    "\n",
    "output_Data_Frame = pd.DataFrame(columns = [\"File Name\", \"Counts\"])\n",
    "channel_Directory = base_Directory + \"/Analysis/All_Images_For_Analysis/\"\n",
    "network_File_Path = base_Directory + \"/Training/Phase_1/Trained_Model/Phase_One_Trained_Network.h5\"\n",
    "\n",
    "network = tf.keras.models.load_model(network_File_Path)\n",
    "\n",
    "def standard_norm(img):\n",
    "    height, width, channels = img.shape\n",
    "    for channel in range(channels):\n",
    "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "    return img\n",
    "\n",
    "# Optimal sRBC Threshold\n",
    "threshold = [90]\n",
    "\n",
    "#Optimal Car-T Threshold\n",
    "#threshold = [40]\n",
    "\n",
    "for image_Name in os.listdir(channel_Directory):\n",
    "    print(\"Analyzing \" + image_Name[:-4])\n",
    "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
    "    if np.max(full_Channel) == int(np.max(full_Channel)) and len(str(np.max(full_Channel))) == len(str(int(np.max(full_Channel)))):\n",
    "        full_Channel = full_Channel.copy()/255.\n",
    "    if len(np.shape(full_Channel)) == 2:\n",
    "        full_Channel = cv2.cvtColor(full_Channel.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    if np.shape(full_Channel)[2] == 4:\n",
    "        full_Channel = full_Channel.copy()[:,:,0:3]\n",
    "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
    "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    else:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
    "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
    "    x_Slider = 0\n",
    "    y_Slider = 0\n",
    "    output_Array = np.zeros((128,128))\n",
    "    for i in range(vertical_Tiles):\n",
    "        x_Slider = 150*i\n",
    "        for j in range(horizontal_Tiles):\n",
    "            y_Slider = 150*j\n",
    "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]\n",
    "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
    "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
    "            output = network.predict(current_Tile_Normalized, verbose = 0)\n",
    "\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
    "            \n",
    "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
    "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
    "            output_Array = np.zeros((128,128))\n",
    "    for i in range(image_Height_Resized):\n",
    "        for j in range(image_Width_Resized):\n",
    "            if output_Image[i,j] != 0:\n",
    "                output_Image[i,j] = 1\n",
    "            else:\n",
    "                continue\n",
    "    blobs, number_Of_Blobs = label(output_Image)\n",
    "    properties = measure.regionprops(blobs)\n",
    "    for thresh in threshold:\n",
    "        centroids = [prop.centroid for prop in properties if prop.area > thresh]\n",
    "        #output_Data_Frame = output_Data_Frame.append(pd.DataFrame([[image_Name,len(centroids)]], columns = [\"File Name\", \"Counts\"]))\n",
    "        output_Data_Frame = pd.concat([output_Data_Frame.copy(), pd.DataFrame([[image_Name,len(centroids)]], columns = [\"File Name\", \"Counts\"])])\n",
    "    display(output_Data_Frame)\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba9fd4",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to save the counts collected to a .csv file for further analysis, or for viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_Data_Frame.to_csv(base_Directory + \"/Analysis/Automated_Counts/Counts_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb07292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
