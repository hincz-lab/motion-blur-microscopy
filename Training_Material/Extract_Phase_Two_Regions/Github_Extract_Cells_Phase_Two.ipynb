{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efc782d",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to import any necessary libraries or packages needed for the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constitutional-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770e27a",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to extract possible \"cells\" for manual classification.\n",
    "\n",
    "The user will have to change the channel_Directory, network_File_Path, and region_Save_Location variables to link to their relevant directories. Notice here how we use the phase one network to identify potential cell candidates, which we will than classify by hand later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transsexual-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 948\n",
      "Analyzing 949\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m128\u001b[39m):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         output_Array[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m output_Array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(output_Array,(\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m150\u001b[39m),interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m     77\u001b[0m output_Image[x_Slider:x_Slider \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m150\u001b[39m, y_Slider: y_Slider \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m150\u001b[39m] \u001b[38;5;241m=\u001b[39m output_Array\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Motion_Blur\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Motion_Blur\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "channel_Directory = \"\"\n",
    "network_File_Path = \"\"\n",
    "region_Save_Location = \"\"\n",
    "\n",
    "network = tf.keras.models.load_model(network_File_Path)\n",
    "\n",
    "def standard_norm(img):\n",
    "    height, width, channels = img.shape\n",
    "    for channel in range(channels):\n",
    "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "    return img\n",
    "\n",
    "def recolor_Image(img):\n",
    "    maximum = np.mean(img) + 4*np.std(img)\n",
    "    minimum = np.mean(img) - 4*np.std(img)\n",
    "    color_Adjusted_Image = (img - minimum)/(maximum - minimum)\n",
    "    color_Adjusted_Image[color_Adjusted_Image < 0] = 0\n",
    "    color_Adjusted_Image[color_Adjusted_Image > 1] = 1\n",
    "    return color_Adjusted_Image\n",
    "    \n",
    "\n",
    "count = 0\n",
    "region_Number = 0\n",
    "cell_Capture_Range = 40\n",
    "for image_Name in os.listdir(channel_Directory):\n",
    "    print(\"Analyzing \" + image_Name[:-4])\n",
    "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
    "    if np.max(full_Channel) == int(np.max(full_Channel)) and len(str(np.max(full_Channel))) == len(str(int(np.max(full_Channel)))):\n",
    "        full_Channel = full_Channel.copy()/255.\n",
    "    if len(np.shape(full_Channel)) == 2:\n",
    "        full_Channel = cv2.cvtColor(full_Channel, cv2.COLOR_GRAY2RGB)\n",
    "    if np.shape(full_Channel)[2] == 4:\n",
    "        full_Channel = full_Channel.copy()[:,:,0:3]\n",
    "    full_Channel = recolor_Image(full_Channel.copy())\n",
    "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
    "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    else:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    full_Channel_Resized[full_Channel_Resized < 0] = 0\n",
    "    full_Channel_Resized[full_Channel_Resized > 1] = 1\n",
    "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
    "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
    "\n",
    "\n",
    "    x_Slider = 0\n",
    "    y_Slider = 0\n",
    "    output_Array = np.zeros((128,128))\n",
    "    for i in range(vertical_Tiles):\n",
    "        x_Slider = 150*i\n",
    "        for j in range(horizontal_Tiles):\n",
    "            y_Slider = 150*j\n",
    "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]\n",
    "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
    "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
    "            output = network.predict(current_Tile_Normalized, verbose = 0)\n",
    "\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
    "            \n",
    "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
    "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
    "            output_Array = np.zeros((128,128))\n",
    "    for i in range(image_Height_Resized):\n",
    "        for j in range(image_Width_Resized):\n",
    "            if output_Image[i,j] != 0:\n",
    "                output_Image[i,j] = 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    blobs, number_Of_Blobs = label(output_Image)\n",
    "    properties = measure.regionprops(blobs)\n",
    "    \n",
    "    for prop in properties:\n",
    "        count = count + 1\n",
    "        if round(prop.centroid[0]) < cell_Capture_Range:\n",
    "            if round(prop.centroid[1]) < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,0:cell_Capture_Range]  \n",
    "            elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,image_Width_Resized - cell_Capture_Range:image_Width_Resized]   \n",
    "            else:\n",
    "                region = full_Channel_Resized[0:cell_Capture_Range,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]\n",
    "        elif round(prop.centroid[1]) < cell_Capture_Range:\n",
    "            if image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,0:cell_Capture_Range]\n",
    "            else:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),0:cell_Capture_Range]\n",
    "        elif image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "            if image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,image_Width_Resized - cell_Capture_Range:image_Width_Resized]\n",
    "            else:\n",
    "                region = full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]              \n",
    "        elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),image_Width_Resized - cell_Capture_Range:image_Width_Resized]            \n",
    "        else:\n",
    "                region = full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]               \n",
    "        plt.imsave(region_Save_Location + \"/Region_\" + str(count) + \".png\",region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
