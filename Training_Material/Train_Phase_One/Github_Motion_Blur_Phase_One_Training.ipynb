{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46256240",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to import all of the necessary libraries and packages to run the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D, Input, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "import shutil\n",
    "import cv2 as cv2\n",
    "\n",
    "from random import randint\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9f860",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to move all original tiles and the one-hot encoded truth arrays to a \"flow folder\". The script will also generate a .csv file, containing file names of images, as well as file names of one-hot encoded truth arrays.\n",
    "\n",
    "Users will have to adjust the base_Directory variable for their own use. Please note the file layout convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Directory = \"\"\n",
    "image_Names = os.listdir(base_Directory + \"Raw_Training_Tiles_Resized/\")\n",
    "mask_Names = os.listdir(base_Directory + \"Training_Tiles_Labeled_And_Layered_Resized/\")\n",
    "flow_Directory = base_Directory + \"Flow_Folder\"\n",
    "data_Frame_Location = base_Directory + \"Excel_Directory/Training_File_Names.csv\"\n",
    "\n",
    "dict = {'X': image_Names, 'Y_True': mask_Names} \n",
    "training_Data_Frame = pd.DataFrame(dict)\n",
    "training_Data_Frame.to_csv(data_Frame_Location)\n",
    "\n",
    "for file in os.listdir(base_Directory + \"Raw_Training_Tiles_Resized/\"):\n",
    "  shutil.copy(base_Directory + \"Raw_Training_Tiles_Resized/\" + file, base_Directory + \"Flow_Folder/\" + file)\n",
    "\n",
    "for file in os.listdir(base_Directory + \"Training_Tiles_Labeled_And_Layered_Resized/\"):\n",
    "  shutil.copy(base_Directory + \"Training_Tiles_Labeled_And_Layered_Resized/\" + file, base_Directory + \"Flow_Folder/\" + file)\n",
    "\n",
    "dict = {'X': np.sort(image_Names), 'Y_True': np.sort(mask_Names)} \n",
    "training_Data_Frame = pd.DataFrame(dict)\n",
    "training_Data_Frame.to_csv(data_Frame_Location)\n",
    "\n",
    "\n",
    "\n",
    "training_Data_Frame = pd.read_csv(data_Frame_Location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c79bf1",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to generate the machine learning network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Phase 1 Models ====================\n",
    "\n",
    "def Phase1_Net(img_size, num_classes):\n",
    "    inputs = Input(shape=img_size + (3,))\n",
    "\n",
    "    x = Conv2D(64,kernel_size = 3, strides = (1,1),\n",
    "                            padding = \"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    \n",
    "    previous_block_concatenate1 = x\n",
    "    x = MaxPooling2D(pool_size = (2,2),\n",
    "                                  strides = (2,2))(x)\n",
    "\n",
    "    x = Conv2D(128,kernel_size = 3, strides = (1,1),\n",
    "                            padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2),\n",
    "                                  strides = (2,2))(x)\n",
    "\n",
    "    previous_block_concatenate2 = x\n",
    "\n",
    "    concate_block_num = 3\n",
    "    for filters in [256, 512, 512]:\n",
    "        x = Conv2D(filters,3, strides = (1,1),\n",
    "                            padding = \"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activations.relu)(x)\n",
    "        x = Conv2D(filters,3, strides = 1,\n",
    "                         padding = \"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activations.relu)(x)\n",
    "        x = MaxPooling2D(pool_size = (2,2),\n",
    "                                  strides = (2,2))(x)\n",
    "        globals()['previous_block_concatenate%s' % concate_block_num] = x\n",
    "        concate_block_num = concate_block_num + 1\n",
    "        print((\"No errors for filter size:\" + str(filters)))\n",
    "\n",
    "\n",
    "\n",
    "    x = Conv2D(512,3, strides = 1,\n",
    "                            padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2),\n",
    "                                  strides = (2,2))(x)\n",
    "\n",
    "    x = Conv2D(512,3, strides = 1,\n",
    "                            padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = Conv2DTranspose(256,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = concatenate([x, previous_block_concatenate5], axis =-1)\n",
    "\n",
    "    x = Conv2DTranspose(256,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = concatenate([x, previous_block_concatenate4],axis=-1)\n",
    "\n",
    "    x = Conv2DTranspose(128,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = concatenate([x, previous_block_concatenate3],axis=-1)\n",
    "    \n",
    "    x = Conv2DTranspose(64,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = concatenate([x, previous_block_concatenate2],axis=-1)\n",
    "\n",
    "\n",
    "    x = Conv2DTranspose(32,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    x = Conv2DTranspose(64,2, strides = (2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "\n",
    "    x = concatenate([x, previous_block_concatenate1],axis=-1)\n",
    "\n",
    "    x = Conv2D(32,3, strides = (1,1),\n",
    "                            padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = Conv2D(num_classes,3, strides = (1,1),\n",
    "                            padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    outputs = Conv2D(num_classes,3, strides = (1,1),\n",
    "                            activation = 'softmax',\n",
    "                            padding = 'same',\n",
    "                            name = 'sRBC_classes')(x)\n",
    "    model = Model(inputs,outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ================ Train Phase 2 Model ================\n",
    "\n",
    "# training the model for a specific amount of epochs \n",
    "def Phase1_train_network(model, X_train, y_train, \n",
    "                        X_test, y_test, epochs):\n",
    "    \n",
    "    train_history = model.fit(X_train, y_train, epochs=epochs, \n",
    "                              validation_data=(X_test, y_test),\n",
    "                              shuffle = True, verbose = 2)\n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabad139",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to create a data generator, which will read tiles into the training method in batches, with augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data_Frame, x_Col, y_Col, directory,tile_Namesake, mask_Namesake, subset = None,\n",
    "                 horizontal_Flips = False, vertical_Flips = False, rotations = False, batch_Size = 32,\n",
    "                 split = False, training_Ratio = 1, shuffle = False, dim = (128,128), number_Of_Channels = 3,\n",
    "                 number_Of_Classes = 2, sample_Mean_Zero_Center_Standarardization = True, number_Of_Training_Images = None):\n",
    "        self.batch_Size = batch_Size\n",
    "        self.df = data_Frame\n",
    "        self.x_Col = x_Col\n",
    "        self.y_Col = y_Col\n",
    "        self.dim = dim\n",
    "        self.directory = directory\n",
    "        self.subset = subset\n",
    "        self.sample_Mean_Zero_Center_Standarardization = sample_Mean_Zero_Center_Standarardization\n",
    "        self.number_Of_Classes = number_Of_Classes\n",
    "        self.number_Of_Channels = number_Of_Channels\n",
    "        self.shuffle = shuffle\n",
    "        self.tile_Names = self.df[self.x_Col]\n",
    "        self.truth_Names = self.df[self.y_Col]\n",
    "        self.tile_Namesake = tile_Namesake\n",
    "        self.mask_Namesake = mask_Namesake\n",
    "        self.horizontal_Flips = horizontal_Flips\n",
    "        self.vertical_Flips = vertical_Flips\n",
    "        self.number_Of_Training_Images = number_Of_Training_Images\n",
    "        self.index_List = np.arange(number_Of_Training_Images) + 1\n",
    "        self.rotations = rotations\n",
    "        self.training_Samples = int(training_Ratio*len(self.index_List))\n",
    "        if split == True:\n",
    "            self.train_Index_List = self.index_List[:self.training_Samples]\n",
    "            self.validate_Index_List = self.index_List[self.training_Samples:]\n",
    "        else:\n",
    "            self.train_Index_List = self.index_List[:]\n",
    "            self.validate_Index_List = []\n",
    "        if self.shuffle == True:\n",
    "            self.on_Epoch_End()\n",
    "    def __len__(self):\n",
    "        return int(len(self.train_Index_List)/self.batch_Size)\n",
    "    def __getitem__(self, index):\n",
    "        if self.subset == \"Training\":\n",
    "            indexes = self.train_Index_List[index*self.batch_Size:(index*self.batch_Size) + self.batch_Size]\n",
    "            X, y_True = self.generate_Batch(indexes)\n",
    "        elif self.subset == \"Validation\":\n",
    "            indexes = self.validate_Index_List[index*self.batch_Size:(index*self.batch_Size) + self.batch_Size]\n",
    "            X, y_True = self.generate_Batch(indexes)\n",
    "        else:\n",
    "            indexes = self.train_Index_List[index*self.batch_Size:(index*self.batch_Size) + self.batch_Size]\n",
    "            X, y_True = self.generate_Batch(indexes)\n",
    "        return X, y_True\n",
    "    def on_Epoch_End(self):\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.train_Index_List)\n",
    "    def generate_Batch(self,indexes):\n",
    "        X = np.zeros((self.batch_Size, *self.dim, self.number_Of_Channels))\n",
    "        y_True = np.zeros((self.batch_Size, *self.dim, self.number_Of_Classes))\n",
    "        for index in range(len(indexes)):\n",
    "            if self.sample_Mean_Zero_Center_Standarardization == True:\n",
    "                img = plt.imread(self.directory + self.tile_Namesake + str(indexes[index]) + \".png\")[:,:,0:3]\n",
    "                if np.max(img) == int(np.max(img)) and len(str(np.max(img))) == len(str(int(np.max(img)))):\n",
    "                    img = img.copy()/255.\n",
    "                if len(np.shape(img)) == 2:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                if np.shape(img)[2] == 4:\n",
    "                    img = img.copy()[:,:,0:3]\n",
    "                mask = np.load(self.directory + self.mask_Namesake + str(indexes[index]) + \".npy\")\n",
    "                img, mask = self.augment_Image(img,mask)\n",
    "                X[index,:,:,:] = self.standard_norm(plt.imread(self.directory + self.tile_Namesake + str(indexes[index]) + \".png\")[:,:,0:3])\n",
    "                y_True[index,:,:,:] = np.load(self.directory + self.mask_Namesake + str(indexes[index]) + \".npy\")\n",
    "            else:\n",
    "                img = plt.imread(self.directory + self.tile_Namesake + str(indexes[index]) + \".png\")[:,:,0:3]\n",
    "                if np.max(img) == int(np.max(img)) and len(str(np.max(img))) == len(str(int(np.max(img)))):\n",
    "                    img = img.copy()/255.\n",
    "                if len(np.shape(img)) == 2:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                if np.shape(img)[2] == 4:\n",
    "                    img = img.copy()[:,:,0:3]\n",
    "                mask = np.load(self.directory + self.mask_Namesake + str(indexes[index]) + \".npy\")\n",
    "                img, mask = self.augment_Image(img,mask)\n",
    "                X[index,:,:,:] = img\n",
    "                y_True[index,:,:,:] = mask\n",
    "        return X, y_True\n",
    "    def standard_norm(self,img):\n",
    "        height, width, channels = img.shape\n",
    "        for channel in range(channels):\n",
    "            img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "        return img\n",
    "    def augment_Image(self, image, mask):\n",
    "        if self.rotations == True:\n",
    "            random_Integer = randint(1,5)\n",
    "            image = np.rot90(image.copy(),random_Integer)\n",
    "            mask = np.rot90(mask.copy(),random_Integer)\n",
    "        \n",
    "        if self.horizontal_Flips == True:\n",
    "            random_Float = random()\n",
    "\n",
    "            if random_Float < 0.5:\n",
    "                image = np.flip(image.copy(),0)\n",
    "                mask = np.flip(mask.copy(),0)\n",
    "        if self.vertical_Flips == True:\n",
    "            random_Float = random()\n",
    "\n",
    "            if random_Float < 0.5:\n",
    "                image = np.flip(image.copy(),1)\n",
    "                mask = np.flip(mask.copy(),1)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db3871",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to train the semantic segmantation machine learning architecture.\n",
    "Note that the number of epochs is intentially made large. Users are not intended to reach the number_Of_Epochs variable. Instead, the learning will be limited by early stopping, given by the patience variable. This variable gives the number of epochs without improvement by the network before training is automatically stopped. Users may need to change the tile_Names_Style and mask_Names_Style variables to match their naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_Names_Style = \"/\" \n",
    "mask_Names_Style = \"/\"\n",
    "img_size = (128,128)\n",
    "num_classes = 2\n",
    "number_Of_Epochs = 1000\n",
    "model = Phase1_Net(img_size, num_classes)\n",
    "#learning hyperparamters for the training optimizer \n",
    "model.compile(Adam(learning_rate=0.001),\n",
    "                 metrics = ['accuracy'],\n",
    "                 loss = tf.keras.losses.CategoricalCrossentropy())\n",
    "train_Gen = DataGenerator(data_Frame=training_Data_Frame,\n",
    "                    x_Col = \"X\",\n",
    "                    y_Col = \"Y_True\",\n",
    "                    directory = flow_Directory,\n",
    "                    vertical_Flips=True,\n",
    "                    horizontal_Flips = True,\n",
    "                    rotations = True,\n",
    "                    split = True,\n",
    "                    training_Ratio = 0.8,\n",
    "                    shuffle = True,\n",
    "                    tile_Namesake = tile_Names_Style,\n",
    "                    mask_Namesake = mask_Names_Style,\n",
    "                    subset = \"Training\",\n",
    "                    number_Of_Training_Images = len(image_Names))\n",
    "validate_Gen = DataGenerator(data_Frame=training_Data_Frame,\n",
    "                    x_Col = \"X\",\n",
    "                    y_Col = \"Y_True\",\n",
    "                    directory = flow_Directory,\n",
    "                    vertical_Flips=False,\n",
    "                    horizontal_Flips = False,\n",
    "                    rotations = False,\n",
    "                    split = True,\n",
    "                    training_Ratio = 0.8,\n",
    "                    shuffle = True,\n",
    "                    tile_Namesake = tile_Names_Style,\n",
    "                    mask_Namesake = mask_Names_Style,\n",
    "                    subset = \"Validation\",\n",
    "                    number_Of_Training_Images = len(image_Names))\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto', restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\"Phase_One.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "training_History = model.fit(train_Gen,\n",
    "                             validation_data = validate_Gen,\n",
    "                                 epochs=number_Of_Epochs, \n",
    "                                 verbose = 1, callbacks = [early, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb37fff",
   "metadata": {},
   "source": [
    "#### Run the following chunk of code to save the trained network architecture and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(base_Directory + \"/Trained_Model/Phase_One_Trained_Network.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
