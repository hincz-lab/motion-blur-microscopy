{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252f930b",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to import any necessary libraries or packages which are needed for the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb494c4c",
   "metadata": {},
   "source": [
    "### Run the following chunk of code to extract all areas and eccentricities of regions identified as \"adhered\" by the phase 1 segmentation network after adjusting the color of the input images.\n",
    "\n",
    "The user will need to change the base_Directory and network_Directory variable, as well as pay careful attention to the directory structure of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Directory = \"\"\n",
    "network_Directory = \"\"\n",
    "blob_Sizes = []\n",
    "blob_Eccentricities = []\n",
    "channel_Directory = base_Directory + \"Analysis/All_Images_For_Analysis/\"\n",
    "network_File_Path = network_Directory\n",
    "\n",
    "network = tf.keras.models.load_model(network_File_Path)\n",
    "\n",
    "def standard_norm(img):\n",
    "    height, width, channels = img.shape\n",
    "    for channel in range(channels):\n",
    "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "    return img\n",
    "\n",
    "def recolor_Image(img):\n",
    "    maximum = np.mean(img) + 4*np.std(img)\n",
    "    minimum = np.mean(img) - 4*np.std(img)\n",
    "    color_Adjusted_Image = (img - minimum)/(maximum - minimum)\n",
    "    color_Adjusted_Image[color_Adjusted_Image < 0] = 0\n",
    "    color_Adjusted_Image[color_Adjusted_Image > 1] = 1\n",
    "    return color_Adjusted_Image\n",
    "\n",
    "\n",
    "for image_Name in os.listdir(channel_Directory):\n",
    "    print(\"Analyzing \" + image_Name[:-4])\n",
    "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
    "    if np.max(full_Channel) == int(np.max(full_Channel)) and len(str(np.max(full_Channel))) == len(str(int(np.max(full_Channel)))):\n",
    "        full_Channel = full_Channel.copy()/255.\n",
    "    if len(np.shape(full_Channel)) == 2:\n",
    "        full_Channel = cv2.cvtColor(full_Channel.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    if np.shape(full_Channel)[2] == 4:\n",
    "        full_Channel = full_Channel.copy()[:,:,0:3]\n",
    "    full_Channel = recolor_Image(full_Channel.copy())\n",
    "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
    "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    else:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
    "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
    "    x_Slider = 0\n",
    "    y_Slider = 0\n",
    "    output_Array = np.zeros((128,128))\n",
    "    for i in range(vertical_Tiles):\n",
    "        x_Slider = 150*i\n",
    "        for j in range(horizontal_Tiles):\n",
    "            y_Slider = 150*j\n",
    "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]\n",
    "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
    "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
    "            output = network.predict(current_Tile_Normalized, verbose = 0)\n",
    "\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
    "            \n",
    "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
    "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
    "            output_Array = np.zeros((128,128))\n",
    "    for i in range(image_Height_Resized):\n",
    "        for j in range(image_Width_Resized):\n",
    "            if output_Image[i,j] != 0:\n",
    "                output_Image[i,j] = 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    blobs, number_Of_Blobs = label(output_Image)\n",
    "    properties = measure.regionprops(blobs)\n",
    "    for prop in properties:\n",
    "        blob_Sizes.append(prop.area)\n",
    "        blob_Eccentricities.append(prop.eccentricity)\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bd9f9",
   "metadata": {},
   "source": [
    "### Run the following code to save the extracted areas and eccentricities as .npy numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(base_Directory + \"Analysis/Extracted_Morphological_Features/Region_Sizes.npy\",blob_Sizes)\n",
    "np.save(base_Directory + \"Analysis/Extracted_Morphological_Features/Region_Eccentricities.npy\",blob_Eccentricities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-leather",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
