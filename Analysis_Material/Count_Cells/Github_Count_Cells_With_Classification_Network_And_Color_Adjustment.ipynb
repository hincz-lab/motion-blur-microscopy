{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0d5349",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to import any useful libraries and packages needed to run the rest of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import label\n",
    "from skimage import measure\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b6ff9",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to count cells in MBM images or MBM video frames using a phase 2 classification network.\n",
    "\n",
    "The user will need to adjust the base_Directory variable, as well as pay careful attention to the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Directory = \"\"\n",
    "\n",
    "\n",
    "output_Data_Frame = pd.DataFrame(columns = [\"File Name\", \"Counts\"])\n",
    "channel_Directory = base_Directory + \"Analysis/All_Images_For_Analysis/\"\n",
    "phase_One_Network_Path = base_Directory + \"Training/Phase_1/Trained_Model/Phase_One_Trained_Network.h5\"\n",
    "phase_Two_Network_Path = base_Directory + \"Training/Phase_2/Trained_Model/Phase_Two_Trained_Network.h5\"\n",
    "\n",
    "confidence_Values = [0.80]\n",
    "\n",
    "network = tf.keras.models.load_model(phase_One_Network_Path)\n",
    "network_Two = tf.keras.models.load_model(phase_Two_Network_Path)\n",
    "\n",
    "def standard_norm(img):\n",
    "    height, width, channels = img.shape\n",
    "    for channel in range(channels):\n",
    "        img[:,:,channel] = (img[:,:,channel] - np.mean(img[:,:,channel]))/np.std(img[:,:,channel])\n",
    "    return img\n",
    "\n",
    "def recolor_Image(img):\n",
    "    maximum = np.mean(img) + 4*np.std(img)\n",
    "    minimum = np.mean(img) - 4*np.std(img)\n",
    "    color_Adjusted_Image = (img - minimum)/(maximum - minimum)\n",
    "    color_Adjusted_Image[color_Adjusted_Image < 0] = 0\n",
    "    color_Adjusted_Image[color_Adjusted_Image > 1] = 1\n",
    "    return color_Adjusted_Image\n",
    "\n",
    "cell_Capture_Range = 40\n",
    "frame_Count = 0\n",
    "for image_Name in os.listdir(channel_Directory):\n",
    "    count = 0\n",
    "    frame_Count = frame_Count + 1 \n",
    "    \n",
    "    print(\"Analyzing \" + image_Name[:-4])\n",
    "    full_Channel = plt.imread(channel_Directory + image_Name)\n",
    "    if np.max(full_Channel) == int(np.max(full_Channel)) and len(str(np.max(full_Channel))) == len(str(int(np.max(full_Channel)))):\n",
    "        full_Channel = full_Channel.copy()/255.\n",
    "    if len(np.shape(full_Channel)) == 2:\n",
    "        full_Channel = cv2.cvtColor(full_Channel.copy(), cv2.COLOR_GRAY2RGB)\n",
    "    if np.shape(full_Channel)[2] == 4:\n",
    "        full_Channel = full_Channel.copy()[:,:,0:3]\n",
    "    full_Channel = recolor_Image(full_Channel.copy())\n",
    "    image_Height, image_Width, channels = np.shape(full_Channel)\n",
    "    if (image_Height % 150) < 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) >= 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    elif (image_Height % 150) >= 75 and (image_Width % 150) < 75:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int(np.floor(image_Width/150)*150), int((np.floor(image_Height/150) + 1)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int((np.floor(image_Height/150) + 1))\n",
    "        horizontal_Tiles = int(np.floor(image_Width/150))\n",
    "    else:\n",
    "        full_Channel_Resized = cv2.resize(full_Channel,(int((np.floor(image_Width/150) + 1)*150), int(np.floor(image_Height/150)*150)), interpolation = cv2.INTER_CUBIC)\n",
    "        vertical_Tiles = int(np.floor(image_Height/150))\n",
    "        horizontal_Tiles = int((np.floor(image_Width/150) + 1))\n",
    "    image_Height_Resized, image_Width_Resized, channels = np.shape(full_Channel_Resized)\n",
    "    output_Image = np.zeros((image_Height_Resized,image_Width_Resized))\n",
    "    x_Slider = 0\n",
    "    y_Slider = 0\n",
    "    output_Array = np.zeros((128,128))\n",
    "    for i in range(vertical_Tiles):\n",
    "        x_Slider = 150*i\n",
    "        for j in range(horizontal_Tiles):\n",
    "            y_Slider = 150*j\n",
    "            current_Tile = full_Channel_Resized[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150,:]\n",
    "            current_Tile = cv2.resize(current_Tile, (128,128), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            current_Tile_Normalized = standard_norm(current_Tile.copy())\n",
    "            current_Tile_Normalized = current_Tile_Normalized[None,:,:,:]\n",
    "            output = network.predict(current_Tile_Normalized, verbose = 0)\n",
    "\n",
    "            for i in range(128):\n",
    "                for j in range(128):\n",
    "                    output_Array[i,j] = np.argmax(output[0,i,j,:])\n",
    "            \n",
    "            output_Array = cv2.resize(output_Array,(150,150),interpolation = cv2.INTER_AREA)\n",
    "            output_Image[x_Slider:x_Slider + 150, y_Slider: y_Slider + 150] = output_Array\n",
    "            output_Array = np.zeros((128,128))\n",
    "    for i in range(image_Height_Resized):\n",
    "        for j in range(image_Width_Resized):\n",
    "            if output_Image[i,j] != 0:\n",
    "                output_Image[i,j] = 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    blobs, number_Of_Blobs = label(output_Image)\n",
    "    properties = measure.regionprops(blobs)\n",
    "    \n",
    "\n",
    "    for confidence in confidence_Values:\n",
    "          count = 0\n",
    "          for prop in properties:\n",
    "                if round(prop.centroid[0]) < cell_Capture_Range:\n",
    "                    if round(prop.centroid[1]) < cell_Capture_Range:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[0:cell_Capture_Range,0:cell_Capture_Range]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))\n",
    "                    elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[0:cell_Capture_Range,image_Width_Resized - cell_Capture_Range:image_Width_Resized]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))   \n",
    "                    else:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[0:cell_Capture_Range,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))\n",
    "                elif round(prop.centroid[1]) < cell_Capture_Range:\n",
    "                    if image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,0:cell_Capture_Range]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))\n",
    "                    else:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),0:cell_Capture_Range]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))\n",
    "                elif image_Height_Resized - prop.centroid[0] < cell_Capture_Range:\n",
    "                    if image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,image_Width_Resized - cell_Capture_Range:image_Width_Resized]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))\n",
    "                    else:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[image_Height_Resized - cell_Capture_Range:image_Height_Resized,int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))              \n",
    "                elif image_Width_Resized - prop.centroid[1] < cell_Capture_Range:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),image_Width_Resized - cell_Capture_Range:image_Width_Resized]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))            \n",
    "                else:\n",
    "                        region = np.reshape(preprocess_input((255*full_Channel_Resized[int(round(prop.centroid[0]) - cell_Capture_Range/2):int(round(prop.centroid[0]) + cell_Capture_Range/2),int(round(prop.centroid[1]) - cell_Capture_Range/2):int(round(prop.centroid[1]) + cell_Capture_Range/2)]).astype(int)),(1,cell_Capture_Range,cell_Capture_Range,3))   \n",
    "                prediction = network_Two.predict(region, verbose = 0)\n",
    "                if np.argmax(prediction) == 0 and prediction[0,np.argmax(prediction)] >= confidence:\n",
    "                    count += 1\n",
    "    output_Data_Frame = pd.concat([output_Data_Frame.copy(), pd.DataFrame([[image_Name,count]], columns = [\"File Name\", \"Counts\"])])\n",
    "    display(output_Data_Frame)\n",
    "display(output_Data_Frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5da3d",
   "metadata": {},
   "source": [
    "### You can run the following chunk of code to save the counts to a .csv file for later analysis or use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_Data_Frame.to_csv(base_Directory + \"/Analysis/Automated_Counts/Counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-seventh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
